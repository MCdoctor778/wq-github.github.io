<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>我的每日记录</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      padding: 40px;
      max-width: 800px;
      margin: auto;
      background-color: #f7f7f7;
    }
    h1 {
      color: #333;
    }
    .entry {
      background: #fff;
      border-left: 5px solid #4CAF50;
      margin-bottom: 20px;
      padding: 20px;
      box-shadow: 0 2px 5px rgba(0,0,0,0.1);
    }
    .date {
      font-weight: bold;
      color: #666;
    }
  </style>
</head>
<body>
  <h1>我的每日记录</h1>

  <div class="entry">
    <div class="date">2025-05-14</div>
    <p>今日：本欲减小模型复杂度，但调试预训练模型通道增加了工作量，暂且不考虑。已暂停数据增强，导致了过拟合，加大了学习率，降低了初始学习权重。</p>
  </div>
  
  <div class="entry">
    <div class="date">2025-05-19</div>
    <p>今日：调参，模型只能学习到部分特征，初步先增大detection_loss的权重，架构目前应该已经够复杂了，对于一个简单任务来说。但模型收敛了，只是效果不太好，说明之前的结构调整和数据调整应当是有效的。</p>
  </div>

  <div class="entry">
    <div class="date">2025-05-20</div>
    <p>今日：调参，出了个bug，梯度溢出了，在param_unet层全都是nan，用o3max试了下，分两次解决了问题，第一次使用梯度裁剪并没有解决问题，考虑是posweight和计数损失的问题；第二次尝试溯源，发现加载完成后是没问题的，问题出现在反向过程，把scaler = GradScaler(init_scale=1024., growth_interval=200)的初始放大倍数缩小，并降低了pos_weight，loss正常了。</p>
  </div>

  <div class="entry">
    <div class="date">2025-05-21</div>
    <p>今日：发现5.17的最终效果是瓶颈，另外在薅gemini的会员，写高等激光技术结课论文。</p>
  </div>
  
  <div class="entry">
    <div class="date">2025-05-23</div>
    <p>今日：这俩天一方面在重顾模型，了解多任务平衡，以及修改损失结构。gemini pro 已get。花费15 $左右。还在调参。</p>
  </div>
  <div class="entry">
    <div class="date">2025-05-26</div>
    <p>今日：调整了loss，加入阳性loss计算筛选，但出现了过拟合，所以启用了数据增强抑制过拟合。但同时出现了梯度溢出。debug---
    1、先启用数据增强 + Early-Stopping（几乎免费）；（已启用数据增强）
    2、同时把 OHNM 提升到 30 % 并观察 val_detection_loss 曲线；（已执行，观测中）
    3、若 FP 仍高，再替换 FocalLoss / 调低 detection_weight；
    4、最后再决定是否需要结构性正则（Dropout）或更大规模的模型集成。
    按经验，前两步即可显著降低 false positive，并让 total / detection loss 在验证集重新下降，过拟合曲线会变得平滑。</p>
  </div>

  <div class="entry">
    <div class="date">2025-05-27</div>
    <p>今日：使用了GMM混合损失，想避免因为多任务权重带来的额外问题。</p>
  </div>

  <div class="entry">
    <div class="date">2025-05-28</div>
    <p>今日：发现不对劲。重新采用的GMM损失似乎并不是很合适。亦或是哪里出错了。重新检查了数据增强部分，可视化检查。损失部分暂时放弃了gmm损失，效果不佳。回到原来的损失，发现参数预测部分是否没必要加blur？虽然还没到详细检查参数的时候，另外detection_logits的导出似乎有问题
    之前一直用的是detection_head，但实际应用中竟然是取的params_unet的第一个通道。。修改了一下，这是逻辑上的大错吧感觉。。另外pos_weight也因此下降了一些，总感觉100太大了，不太合适。继续调参--</p>
  </div>
  
  <div class="entry">
    <div class="date">2025-05-28</div>
    <p>  局部最优 分布在角落(可能和网络结构有关)
1、先提高学习率 降低权重衰减
全黑 提高学习率降低loss
2、提高定位权重 
3、调整冻结层
4、调整损失 对于零目标惩罚
5、加大损失权重惩罚</p>
  </div>



  <!-- 新的日志可以在这里复制粘贴添加 -->
</body>
</html>
